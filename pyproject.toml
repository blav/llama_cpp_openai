[tool.poetry]
name = "llama_cpp_openai"
version = "0.1.1"
description = "Lightweight OpenAI API server on top of Llama local models. Suitable for combined use with Microsoft AutoGen."
authors = ["blav <blav@actar.us>"]
readme = "README.md"
license = "Apache-2.0"
classifiers = [
  "Intended Audience :: Developers",
  "Programming Language :: Python :: 3.8",
  "Programming Language :: Python :: 3.9",
  "Programming Language :: Python :: 3.10",
  "Programming Language :: Python :: 3.11",
  "Operating System :: OS Independent",
  "Operating System :: POSIX",
  "Operating System :: MacOS",
  "Operating System :: POSIX :: Linux",
  "Operating System :: Microsoft :: Windows",
  "Topic :: Software Development :: Libraries :: Python Modules",
  "License :: OSI Approved :: Apache Software License"
]

[tool.poetry.dependencies]
python = ">=3.8,<3.12"
fastapi = "^0.105.0"
llama-cpp-python = "^0.2.22"
pydantic = "^2.5.2"
uvicorn = "^0.24.0.post1"


[tool.poetry.group.dev.dependencies]
pytest = "^7.4.3"
httpx = "^0.25.2"
pyautogen = "^0.2.2"

[tool.poetry.scripts]
generate-openai-model = "scripts.generate_openai_model:main"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
